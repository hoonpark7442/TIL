> https://www.youtube.com/watch?v=mPB2CZiAkKM 참고

> [정리잘한곳](https://lion-king.tistory.com/entry/Redis-what-is)
# 레디스
- 자료구조가 아토믹하기 때문에 레이스컨디션 피할 수 있다.(그래도 잘못하면 발생)
- 외부의 컬렉션을 잘 이용하는 것으로 여러가지 개발 시간 단축시킬 수 있고 문제 줄여줄 수 있기 때문에 중요
- 사용처
	- 리모트 데이터 스토어
		- a서버, b서버 등에서 데이터 공유하고 싶을 때
	- 레디스 자체가 아토믹을 보장해줌. 싱글스레드라
	- 주로 많이 쓰이는 곳들
		- 인증 토큰 등을 저장(스트링 또는 해쉬)
		- 랭킹 보드로 사용(솔티드셋)
		- 유저 api limit

# 레디스운영
## 메모리 관리를 잘하자
	- 레디스는 인메모리 데이터 스토어
	- 피지컬 메모리 이상을 사용하면 문제가 발생
		- 스왑이 있다면 스왑 사용으로 해당 메모리 페이지 접근시마다 늦어짐. 메모리 페이지를 디스크에 저장해놓고 필요하면 그걸 로딩시키고 이런식으로 처리. 스왑이 한번이라도 발생한 메모리 페이지는 계속 스왑이 일어남. 그 메모리 페이지에 접근해야할 키가 있으면 그 키 접근할때마다 디스크에 접근하게 됨
		- 스왑이 없다면 OOM 발생 등으로 해서 죽어버림
	- 맥스메모리를 설정하더라도 이보다 더 사용할 가능성이 큼. 맥스메모리는 레디스가 아는 자기가 사용하는 메모리.
		- 레디스는 메모리풀을 사용하는게 아니고 메모리할당해제를 jmalloc 같은 메모리 얼로케이터 사용. 메모리 얼로케이터 구현에 따라서 성능이 달라짐. 
		- 메모리 얼로케이터가 지웠다고 하지만 메모리 잡고 있는 경우도 있고...
		- 이러한 메모리얼로케이터, 즉 jemalloc 때문에 레디스는 자기가 사용하는 메모리가 정확히 얼만지 알 수가 없음.
		- 메모리 페이지 사이즈가 4096이라고 하면 우리가 1바이트만 할당해달라고 했을 때 jmalloc은 메모리 페이지 단위로 할당해야돼서 4096을 가져와야 함
		- 내가 0~4095 안에 있는걸 달라고 하면 그안에서 할당해 줄텐데 4096을 달라고 하면 새 페이지를 할당해서 줘야함. 나는 4097바이트를 사용하고 있는데 8k를 할당한거임. 이게 즉 메모리 파편화.
		- 맥스메모리 설정하더라도 메모리 관리를 해야함
	- rss 값을 모니터링 해야 함
	- 많은 업체가 현재 메모리를 사용해서 swap을 쓰고 있다는 것을 모를 때가 많음

	- 큰 메모리 단위를 사용하는 인스턴스 하나보다는 적은 메모리를 사용하는 인스턴스 여러개가 안전함
		- 마스터 슬레이브 를 사용하게 되면 포크를 하게 되어있다. 리드가 많은 서비스는 전혀 문제 없는데 라이트가 헤비한 레디스는 최대 메모리를 2배까지 쓸 수도 있다. 처음에 포크했을때는 cow 라고 해서 메모리 리드만 일어나면 메모리 실제 복사를 안하는데 라이트가 일어나면 그때 메모리 복사해서 메모리를 더 써야 된다. 라이트가 헤비하게 일어나면 최대 2배까지도 쓸 수 있게 됨.
		- 24기가 인스턴스 < 8기가 인스턴스 x 3
		- 24기가 짜리면 포크일어나서 최악의 경우 48기가 메모리를 사용하게 되버리게 된다. 그래서 더 작은 단위로 하면 좀 더 안전
	- 레디스는 메모리 파편화가 발생할 수 있음. 4.x대 부터 메모리 파편화를 줄이도록 jemalloc에 힌트를 주는 기능이 들어갔으나 jemalloc 버전에 따라서 다르게 동작할 수 있음
	- 3.x대 버전의 경우
		- 실제 used memory는 2기가로 보고가 되지만 11기가의 rss를 사용하는 경우가 자주 발생
	- 다양한 사이즈를 가지는 데이터 보다는 유사한 크기의 데이터를 가지는 경우가 유리. 메모리 파편화가 좀 덜 일어나게끔..

## 메모리가 부족할 때는?
	- cache is cash
		- 좀 더 메모리 많은 장비로 마이그레이션
		- 메모리가 빡빡하면 마이그레이션 주에 문제가 발생할 수도..
	- 있는 데이터 줄이기
		- 데이터를 일정 수준에서만 사용하도록 특정 데이터를 줄임
		- 다만 이미 스왑을 사용중이라면 프로세스를 재시작해야함

## 메모리 줄이기 위한 설정
	- 기본적으로 컬렉션 들은 다음과 같은 자료구조를 사용
		- hash -> hash table을 하나 더 사용
		- sorted set -> skiplist와 hash table을 이용
		- set -> hashtable 사용
		- 해당 자료구조들은 메모리를 많이 사용함
	- Ziplist를 이용하자.

## Ziplist 구조
	- 인메모리 특성상 적은 개수라면 선형 탐색을 하더라도 빠르다.
	- list, hash, sorted set 등을 ziplist로 대체해서 처리하는 설정이 존재

## O(n) 관련 명령어는 주의하자
	- 레디스는 싱글 스레드
		- 그러면 레디스가 동시에 여러 개의 명령을 처리할 수 있을까? 한 번에 하나만 처리 가능
		- 참고로 단순한 get/set의 경우 초당 10만 TPS 이상 가능(CPU 속도에 영향 받음)
		- 만약 10000개의 작업이 있고 첫번째 꺼가 1초가 걸린다하고 최대 타임아웃이 200ms라하면 뒤에 9999개 다 뻥나는 거임
	- 대표적인 O(n) 명령어들
		- keys
		- flushall, flushdb
		- delete collections
		- get all collections
	- 대표적인 실수 사례
		- 키가 백만개 이상인데 확인을 위해 keys 명령을 사용하는 경우
			- 모니터링 스크립트가 일초에 한번씩 keys를 호출하는 경우도..
		- 아이템이 몇만개든 hash, sorted set, set에서 모든 데이터를 가져오는 경우
		- 예전의 spring security oauth redis TokenStore
	- keys는 어떻게 대체?
		- scan 명령을 사용하는 것으로 하나의 긴 명령을 짧은 여러번의 명령으로 바꿀 수 있다. 스캔은 커서 방식
	- 컬렉션의 모든 아이템을 가져와야 할 때?
		- 컬렉션의 일부만 가져오거나..
			- sorted set
		- 큰 컬렉션을 작은 여러개의 컬렉션으로 나눠서 저장
			- Userranks -> Userranks1, Userranks2, ...
			- 하나당 몇천개 안쪽으로 저장하는게 좋음
	- Spring securiy oauth Redis TokenStore 이슈
		- Access Toekn의 저장을 List(O(n)) 자료구조를 통해서 이루어짐
			- 검색, 삭제시에 모든 아이템을 매번 찾아봐야 함. 100만개쯤 되면 전체 성능에 영향을 줌
			- 현재는 set(O(1))을 이용해서 검색, 삭제를 하도록 수정되어 있음

# Redis Replication

- Async Relication
	- Replication lag이 발생할 수 있다.
- 'Relicaof'(>=5.0.0) or 'slaveof' 명령으로 설정 가능
	- Replicaof hostname port
- dbms로 보면 statement replication가 유사

## Redis Replication 시 주의할 점
- replication 과정에서 fork가 발생하므로 메모리 부족이 발생할 수 있다.
- Redis-cli --rdb 명령은 현재 상태의 메모리 스냅샷을 가져오므로 같은 문제를 발생시킴
- aws나 클라우드의 redis는 좀 다르게 구현되어서 좀 더 해당 부분이 안정적
- 많은 대수의 레디스 서버가 레플리카를 두고 있다면
	- 네트워크 이슈나 사람의 작업으로 동시에 replication이 재시도 되도록 하면 문제가 발생할 수 있음
	- ex) 같은 네트워크 안에서 30기가를 쓰는 레디스 마스터 100대 정도가 리플리케이션을 동시에 재시작하면 어떤 일이 벌어질 수 있을까?

## redis.conf 권장설정 팁
- Maxclient 설정 높게. 이거 한번에 네트워크 접근 가능한 수
- rdb/aof 설정 off
- 특정 커맨드 disable
	- keys
	- aws의 elasticcache는 이미 하고 있음
- 전체 장애의 90% 이상이 keys와 save 설정을 사용해서 발생
- 적절한 ziplist 설정
- 보통 실무에선 rdb/aof 설정 off 해두고 혹시나 필요하면 슬레이브에서만. 마스터는 꺼놓고

## redis 데이터 분산
- 데이터의 특성에 따라서 선택할 수 있는 방법이 달라진다.
	- 캐시 데이터냐 psersistent 데이터냐

## 데이터 분산 방법
- application 레벨
	- consistent hashing
		- twemproxy를 사용하는 방법으로 쉽게 사용 가능
	- sharding
		- 가장 쉬운 방법은 range. 그냥 특정 range를 정의하고 해당 range에 속하면 거기에 저장. key 500은 1~1000 사이에 해당되는 곳에 저장하는 식. 
		- 1~1000 을 넘어서는, 1001이 들어오면 1001~2000 하나 더 만들어서 거기에 저장.
		- 모듈러로 할 수도 있고... 이건 샤딩을 따로 공부해야 할듯
- redis cluster
	- hash 기반으로 slot 16384로 구분
		- hash알고리즘은 crc16을 사용
		- slot = crc16(key) % 16384
		- key가 key{hashkey} 패턴이면 실제 crc16에 hashkey가 사용된다.
		- 특정 레디스 서버는 이 slot range를 가지고 있고, 데이터 마이그레이션은 이 슬롯 단위의 데이터를 다른 서버로 전달하게 된다(migrateCommand 이용)

## redis failover
- coordinator 기반 failover
- vip/dns 기반 failover
- redis cluster 사용














